{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO003BaSDEqpN8Gu5y7BIcx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinxWycman/MACHINE-LEARNING/blob/main/KNN_python_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNLlkYWvKudH",
        "outputId": "7c19b2ca-46eb-4a6f-f556-bea5a147b52e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.datasets import load_iris\n",
        "# Load the Iris dataset (a built-in dataset in scikit-learn)\n",
        "data = load_iris()\n",
        "X = data.data # Features\n",
        "y = data.target # Target (class labels)\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Create a KNN classifier with a specified number of neighbors (K)\n",
        "k = 3\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "# Fit the model to the training data\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "# Make predictions on the test data\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "# Calculate the accuracy and print the classification report\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=data.target_names)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this code, we import the necessary libraries, including scikit-learn, which provides the KNeighborsClassifier for KNN classification. We load the Iris dataset, a well-known dataset for classification, which contains features (sepal length, sepal width, petal length, petal width) and class labels (setosa, versicolor, virginica). We split the dataset into training and testing sets using train_test_split. We create a KNN classifier with a specified number of neighbors (K), in this case, k = 3. We fit the KNN classifier to the training data using the fit() method. We make predictions on the test data using the predict() method. We calculate the accuracy of the model and generate a classification report using scikit-learn's accuracy_score and classification_report functions.**"
      ],
      "metadata": {
        "id": "uskHOmfHK4ly"
      }
    }
  ]
}